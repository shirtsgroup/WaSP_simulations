{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for analyzing simulation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.catch_warnings(record=True)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import logging\n",
    "from polysaccharide2.genutils.logutils.IOHandlers import LOG_FORMATTER\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format =LOG_FORMATTER._fmt,\n",
    "    datefmt=LOG_FORMATTER.datefmt,\n",
    "    force=True\n",
    ")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mdtraj\n",
    "from openmm.unit import Unit\n",
    "from openmm.unit import nanometer\n",
    "\n",
    "from polysaccharide2.analysis import mdtrajutils\n",
    "from polysaccharide2.genutils.fileutils.pathutils import assemble_path\n",
    "from polysaccharide2.openmmtools.serialization import SimulationPaths, SimulationParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = Path('wasp_sims')\n",
    "mol_dirs = {\n",
    "    path.stem : path\n",
    "        for path in raw_data_dir.iterdir()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('analysis_output/data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "colina_dir   = data_dir / 'colina_data'\n",
    "openff_dir   = data_dir / 'openff_data'\n",
    "combined_dir = data_dir / 'combined_data'\n",
    "\n",
    "for super_dir in (openff_dir, combined_dir, colina_dir):\n",
    "    super_dir.mkdir(exist_ok=True)\n",
    "    for subdir_name in ('rdfs', 'props'):\n",
    "        subdir = super_dir / subdir_name\n",
    "        subdir.mkdir(exist_ok=True)\n",
    "        globals()[f'{super_dir.name}_{subdir_name}'] = subdir # assign to variables in namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dir  =  data_dir / 'figures'\n",
    "figure_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for subdir_name in ('rdfs', 'props'):\n",
    "    subdir = figure_dir / subdir_name\n",
    "    subdir.mkdir(exist_ok=True)\n",
    "    globals()[f'{figure_dir.name}_{subdir_name}'] = subdir # assign to variables in namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing individual trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rad : float = 0.0\n",
    "max_rad : float = 2.0\n",
    "rad_unit : Unit = nanometer\n",
    "stride : int = 1\n",
    "prevent_overwrites : bool = False\n",
    "\n",
    "for i, sim_paths_path in enumerate(raw_data_dir.glob('**/production/*_paths.json')):\n",
    "    working_dir = sim_paths_path.parent\n",
    "    assert(working_dir.is_dir())\n",
    "    prefix = working_dir.name\n",
    "\n",
    "    LOGGER.info(f'Analyzing trajectory found in: {working_dir} (# {i + 1})')\n",
    "    sim_paths = SimulationPaths.from_file(sim_paths_path)\n",
    "    sim_params = SimulationParameters.from_file(sim_paths.parameters_path)\n",
    "\n",
    "    # load MDTraj trajectories\n",
    "    LOGGER.info(f'Loading trajectory from {sim_paths.trajectory_path}')\n",
    "    traj = mdtraj.load(sim_paths.trajectory_path, top=sim_paths.topology_path, stride=stride)\n",
    "    LOGGER.info('Stripping solvent')\n",
    "    traj_no_solv = traj.remove_solvent(inplace=False)\n",
    "    unique_elems = mdtrajutils.unique_elem_types(traj_no_solv)\n",
    "\n",
    "    # computing and saving shape property time series'\n",
    "    if (sim_paths.time_data_path is None) or not (sim_paths.time_data_path.exists() and prevent_overwrites):\n",
    "        prop_data = mdtrajutils.acquire_time_props(traj_no_solv, time_points=sim_params.integ_params.time_points[::stride]) \n",
    "        LOGGER.info('Computed time series\\' from trajectory')\n",
    "        time_data_path = assemble_path(working_dir, prefix, extension='csv', postfix='time_series')\n",
    "        prop_data.to_csv(time_data_path, index=False)\n",
    "        sim_paths.time_data_path = time_data_path\n",
    "\n",
    "    # RDFs\n",
    "    ## determine IDs of relevant atom pairs\n",
    "    if (sim_paths.spatial_data_path is None) or not (sim_paths.spatial_data_path.exists() and prevent_overwrites):\n",
    "        pair_dict = {\n",
    "            'chain O - water O' : traj.top.select_pairs('not water and element O', 'water and element O'),\n",
    "            # 'water O - water O' : traj.top.select_pairs('water and element O', 'water and element O') # too many waters, prohibitive memory usage\n",
    "        }\n",
    "        \n",
    "        if 'N' in mdtrajutils.unique_elem_types(traj):\n",
    "            pair_dict['chain N - water O'] = traj.top.select_pairs('not water and element N', 'water and element O')\n",
    "\n",
    "        ## computing and saving RDFs \n",
    "        rdf_data = mdtrajutils.acquire_rdfs(traj, pair_dict, min_rad=min_rad, max_rad=max_rad, rad_unit=rad_unit)\n",
    "        LOGGER.info('Computed radial distribution functions (RDFs) from trajectory')\n",
    "        rdf_data_path = assemble_path(working_dir, prefix, extension='csv', postfix='rdfs')\n",
    "        rdf_data.to_csv(rdf_data_path, index=False)\n",
    "        sim_paths.spatial_data_path = rdf_data_path\n",
    "\n",
    "    LOGGER.info(f'Saving updated paths to {sim_paths_path}\\n') # add newline for breathing room\n",
    "    sim_paths.to_file(sim_paths_path) # update JSON file with paths on disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collating individually processed data into unified collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_fns = {\n",
    "    'observables'   : np.mean,\n",
    "    'uncertainties' : np.std\n",
    "}\n",
    "\n",
    "total_data_props = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))\n",
    "total_data_rdfs  = defaultdict(lambda : defaultdict(lambda : defaultdict(pd.DataFrame)))\n",
    "\n",
    "for i, sim_paths_path in enumerate(raw_data_dir.glob('**/production/*_paths.json')):\n",
    "    # extract level info from simulation filetree\n",
    "    working_dir = sim_paths_path.parent\n",
    "    assert(working_dir.is_dir())\n",
    "    mol_name, charge_method, conf_name, prefix = str(working_dir.relative_to(raw_data_dir)).split('/')\n",
    "\n",
    "    # load analyzed data\n",
    "    sim_paths = SimulationPaths.from_file(sim_paths_path)\n",
    "    sim_params = SimulationParameters.from_file(sim_paths.parameters_path)\n",
    "\n",
    "    # reading property data\n",
    "    time_data = pd.read_csv(sim_paths.time_data_path)\n",
    "    time_steps, time_samples = mdtrajutils.props_to_plot_data(time_data)\n",
    "    for prop_name, time_series in time_samples.items():\n",
    "        total_data_props[mol_name][charge_method][prop_name].append(time_series.mean()) # take equilibrium average over each time series\n",
    "\n",
    "    # reading RDF data\n",
    "    rdf_data = pd.read_csv(sim_paths.spatial_data_path)\n",
    "    radii_openff, rdfs = mdtrajutils.rdfs_to_plot_data(rdf_data)\n",
    "    for atom_pair_name, rdf in rdfs.items():\n",
    "        total_data_rdfs[mol_name][charge_method][atom_pair_name][conf_name] = rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing shape properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mol_name, mol_dict in total_data_props.items():\n",
    "    dframe = pd.DataFrame.from_dict({\n",
    "        f'Sage 2.0.0 - {chg_method}' : {\n",
    "            (stat_name, prop_name) : stat_fn(prop_data)\n",
    "                for stat_name, stat_fn in stat_fns.items()\n",
    "                    for prop_name, prop_data in data_dict.items()\n",
    "        }\n",
    "        for chg_method, data_dict in mol_dict.items()\n",
    "    })\n",
    "    # dframe.to_csv(openff_data_props / f'{mol_name}.csv') # index deliberately left in\n",
    "    dframe.to_csv(openff_data_props / f'{mol_name}.csv') # index deliberately left in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref_data_dir in colina_data_props.iterdir():\n",
    "    filename = ref_data_dir.name\n",
    "\n",
    "    new_data = pd.read_csv(openff_data_props / filename, index_col=[0, 1])\n",
    "    ref_data = pd.read_csv(ref_data_dir         , index_col=[0, 1])\n",
    "    data = pd.concat([new_data, ref_data], axis=1)\n",
    "\n",
    "    data.to_csv(combined_data_props / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing RDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mol_name, mol_dict in total_data_rdfs.items():\n",
    "    df_dict = defaultdict(defaultdict)\n",
    "\n",
    "    for chg_method, data_dict in mol_dict.items():\n",
    "        for elem_pair, rdf_data in data_dict.items():\n",
    "            framework = f'Sage 2.0.0 - {chg_method}'\n",
    "            df_dict[framework][(elem_pair, radii_openff.columns[0])] = radii_openff['Radius (nanometer)'].to_list()\n",
    "            for stat_name, stat_fn in stat_fns.items():\n",
    "                df_dict[framework][(elem_pair, stat_name)] = list(stat_fn(rdf_data.to_numpy(), axis=1))\n",
    "\n",
    "    dframe = pd.DataFrame.from_dict(df_dict)\n",
    "    dframe.to_csv(openff_data_rdfs / f'{mol_name}.csv') # index deliberately left in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in openff_data_rdfs.iterdir():\n",
    "    filename = path.name\n",
    "    openff_rdfs = pd.read_csv(path, index_col=(0, 1))\n",
    "    colina_rdfs = pd.read_csv(colina_data_rdfs / filename, index_col=(0, 1))\n",
    "\n",
    "    combined_rdfs = pd.concat([openff_rdfs, colina_rdfs], axis=1)\n",
    "    combined_rdfs.to_csv(combined_data_rdfs / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-pdb-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
